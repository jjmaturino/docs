---
title: Tokenize
---

You can get privacy-conserving text and image embeddings from
[available models](/options/llms) using a call to the `/embeddings` REST
API endpoint or any of the official SDKs (Python, Go, Rust, JS, or cURL).

## Generate Embeddings

To generate embeddings, you can use the following code examples. Depending on your
preference or requirements, select the appropriate method for your application.
This functionality accepts text and image inputs, and supports batching multiple
inputs. The Go REST API only supports images that are input as a base64 encoded
string, whereas the python client supports image files, image urls, and images
encoded in a base64 string.

<CodeBlocks>
    <CodeBlock title="Python">
        ```python
        import os
        import json

        from predictionguard import PredictionGuard

        # Set your Prediction Guard token as an environmental variable.
        os.environ["PREDICTIONGUARD_API_KEY"] = "<api key>"

        client = PredictionGuard()

        response = client.tokenize.create(
            model="Hermes-2-Pro-Llama-3-8B",
            input="This is a tokenize example."
        )

        print(json.dumps(
        response,
        sort_keys=True,
        indent=4,
        separators=(',', ': ')
        ))
        ```
    </CodeBlock>

    <CodeBlock title="Go">
        ```go
        package main

        import (
        "context"
        "fmt"
        "log"
        "os"
        "time"

        "github.com/predictionguard/go-client"
        )

        func main() {
        if err := run(); err != nil {
        log.Fatalln(err)
    }
        ```
    </CodeBlock>

    <CodeBlock title="Rust">
        ```rust
        extern crate prediction_guard as pg_client;
        ```
    </CodeBlock>

    <CodeBlock title="NodeJS">
        ```js
        import * as pg from 'predictionguard';

        const client = new pg.Client('https://api.predictionguard.com', process.env.PREDICTIONGUARD_API_KEY);

        ```
    </CodeBlock>

    <CodeBlock title="cURL">
    ```bash
    curl -i -X POST https://api.predictionguard.com/tokenize \
    -H "Authorization: Bearer ${PREDICTIONGUARD_API_KEY}" \
    -H "Content-Type: application/json" \
    -d '{
        "model": "Hermes-2-Pro-Llama-3-8B",
        "input": "This is a tokenize example."
    }'
    ```
    </CodeBlock>
</CodeBlocks>

The output will look something like this.

```json
{
    "id": "token-61dd03d2-76b4-4261-9543-736d82f86e8c",
    "object": "tokens",
    "created": 1729884596,
    "model": "Hermes-2-Pro-Mistral-7B",
    "tokens": [
    {
        "id": 1,
        "start": 0,
        "stop": 0,
        "text": ""
    },
    {
        "id": 851,
        "start": 0,
        "stop": 4,
        "text": "This"
    },
    ...
```

This approach presents a straightforward way for readers to choose and apply the
code example that best suits their needs for generating text completions using
either Python, Go, Rust, JS, or cURL.